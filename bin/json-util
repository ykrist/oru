#!/usr/bin/env python
import csv
import os
import argparse
import sys
import itertools
import fnmatch
import json

def convert_filename(fn, args):
    if not args.kd:
        fn = os.path.basename(fn)
    if not args.ke:
        fn, _ = os.path.splitext(fn)
    return fn


def error(*args, exit=True, **kwargs):
    kwargs['file'] = sys.stderr
    print('error:', *args, **kwargs)
    if exit:
        sys.exit(1)

def recursive_merge(d1, d2):
    """Merge dictionaries d1 and d2 recursively.  Values from d2 take precedence."""
    new = d1.copy()

    for k,v1 in d1.items():
        if k in d2:
            v2 = d2[k]
            if isinstance(v1, dict) and isinstance(v2, dict):
                new[k] = recursive_merge(v1,v2)
            else:
                new[k] = v2

    for k,v in d2.items():
        if k not in new:
            new[k] = v

    return new


def flatten_dictionary(d, _prefix=()):
    new_d = {}
    for key in d:
        new_key = _prefix + (key,)
        if isinstance(d[key], dict) and len(d[key]) > 0:
            new_d.update(flatten_dictionary(d[key], new_key))
        else:
            new_d[new_key] = d[key]
    return new_d

def restore_dictionary(d):
    new_d = {}
    for reckey in d:
        current_d = new_d
        for key in reckey[:-1]:
            if key not in current_d:
                current_d[key] = {}
            current_d = current_d[key]
        current_d[reckey[-1]] = d[reckey]
    return new_d



def main(args):
    input_files = args.input
    if input_files.count('-') > 1:
        error('STDIN given multiple times.')

    if args.insert is not None:
        if len(input_files) <= 1:
            error("At least 2 input files are required.")
        elif len(input_files)  - 1 < len(args.insert):
            error("Too many field names.")
        args.insert.extend(map(lambda fn : convert_filename(fn, args), input_files[len(args.insert)+1:]))

    data = []
    for i,f in enumerate(input_files):
        if f == '-':
            input_files[i] = 'STDIN'
            d = json.loads(sys.stdin.read())
        else:
            with open(f, 'r') as fp:
                d = json.load(fp)
        if len(data) > 0:
            if args.merge:
                data[0] = recursive_merge(data[0], d)
            elif args.insert is not None:
                data[0][args.insert[i-1]] = d
        else:
            data.append(d)

    if args.merge or args.insert is not None:
        input_files = ['MERGED']

    restore = False
    if args.patterns is not None or args.csv:
        restore = not (args.flatten or args.csv)
        args.flatten = True


    if args.flatten:
        for i in range(len(data)):
            data[i] = flatten_dictionary(data[i])

    if args.patterns is not None:
        for i in range(len(data)):
            patterns = tuple(map(lambda x: x.split(args.level_sep), args.patterns))
            for key in list(data[i].keys()):
                for pattern in patterns:
                    if len(key) >= len(pattern) and all(fnmatch.fnmatch(k, p) for k, p in zip(key, pattern)):
                        break
                else:
                    del data[i][key]

    if restore:
        for i in range(len(data)):
            data[i] = restore_dictionary(data[i])
    elif args.flatten:
        for i in range(len(data)):
            data[i] = {args.level_sep.join(k) : v for k,v in data[i].items()}

    if args.output is not None:
        fp = open(args.output, 'w')
        closefile = True
    else:
        fp = sys.stdout
        closefile = False

    if args.csv:
        csv_fields = set(itertools.chain(*map(lambda r: r.keys(), data)))

        index_field_name = 'index'
        index_suffix = 0
        while index_field_name in csv_fields:
            index_suffix += 1
        if index_suffix > 0:
            index_field_name += str(index_suffix)

        csv_fields = [index_field_name] + sorted(csv_fields)
        csv_writer = csv.DictWriter(fp, csv_fields, extrasaction='ignore')
        csv_writer.writeheader()

        for r, fname in zip(data, input_files):
            r[index_field_name] = convert_filename(fname, args)
            csv_writer.writerow(r)

    else:
        if len(data) == 1:
            data = data[0]
        json.dump(data ,fp, indent='\t')
        fp.write('\n')
    if closefile:
        fp.close()


if __name__ == '__main__':
    p = argparse.ArgumentParser()
    p.add_argument("input", type=str, nargs='+',
                   help='Input JSON files, set to - for STDIN. ')
    p.add_argument("-o", "--output", type=str, default=None,
                   help="Save the result to a file rather than printing to STDOUT.")
    group = p.add_mutually_exclusive_group()
    group.add_argument("-i", "--insert", nargs='*', type=str,
                   help="Insert all JSON files after the first, into the first.  "
                        "For each input JSON file after the first, this option requires a JSON field name to be "
                        "supplied.")
    group.add_argument("-m", "--merge", action='store_true',
                   help= "Merge input files recursively before any operations.")
    p.add_argument("--flatten", action='store_true',
                   help="Flatten JSON to produce output that is exactly 1 level deep.")
    p.add_argument("-l","--level-sep",type=str,default='.',
                   help="Separator to use for JSON levels whhen producing flattened output, and specifying "
                        "filter patterns.  Defaults is `.`")
    p.add_argument("-ke", action="store_true",
                   help="Keep file extension when converting input filenames")
    p.add_argument("-kd", action="store_true",
                   help="Keep directories when converting input filenames")
    p.add_argument("-f", "--filter", type=str, dest='patterns', action='append',
                   help="Select fields from JSON file.  Use a `.` to access nested fields.  "
                         "Standard wildcard matching is supported.  Use this option multiple times to specify"
                         " several patterns at once")
    p.add_argument("--csv", action='store_true',
                   help="Convert 1 or more JSON files into a CSV file, where each JSON file is one row in the output."
                        "Implies `--flatten`.")
    # p.add_argument("-p", "--print", action='store_true',
    #                help="Pretty print the output rather than output a JSON string (the default).")

    if len(sys.argv) > 1:
        args = p.parse_args(sys.argv[1:])
        main(args)
    else:
        p.print_usage()
        sys.exit(1)



